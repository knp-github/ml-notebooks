{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982d6c3c",
   "metadata": {},
   "source": [
    "\n",
    "# JD Equipment Classifier (Keras, Synthetic Dataset)\n",
    "\n",
    "This notebook trains a **5-class image classifier** (tractor, combine, sprayer, skidsteer, baler) using the synthetic data you generated:\n",
    "- Images: `/mnt/data/jd_images.npy` (N, 128, 128, 3)\n",
    "- Labels CSV: `/mnt/data/jd_labels.csv` with columns: `image_id, class_name, class_id, split`\n",
    "\n",
    "> You can later swap to real images with the same pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, random, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_IMAGES = \"/mnt/data/jd_images.npy\"\n",
    "DATA_LABELS = \"/mnt/data/jd_labels.csv\"\n",
    "\n",
    "assert os.path.exists(DATA_IMAGES), f\"Missing: {DATA_IMAGES}\"\n",
    "assert os.path.exists(DATA_LABELS), f\"Missing: {DATA_LABELS}\"\n",
    "\n",
    "print(\"Found:\", DATA_IMAGES, DATA_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = (128, 128)        # matches the synthetic generator\n",
    "NUM_CLASSES = 5              # tractor, combine, sprayer, skidsteer, baler\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3                   # increase when running on GPU\n",
    "LR = 1e-3\n",
    "MODEL_OUT = \"/mnt/data/jd_equipment_classifier.h5\"\n",
    "CLASS_INDEX_JSON = \"/mnt/data/jd_class_index.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load arrays and labels\n",
    "X = np.load(DATA_IMAGES)                 # uint8\n",
    "y_df = pd.read_csv(DATA_LABELS)         # includes class_id and split\n",
    "\n",
    "# Basic checks\n",
    "print(X.shape, X.dtype)\n",
    "print(y_df.head())\n",
    "\n",
    "# Normalize images to [0,1]\n",
    "X = X.astype(\"float32\") / 255.0\n",
    "y = y_df[\"class_id\"].astype(\"int32\").values\n",
    "\n",
    "# Build split masks\n",
    "train_mask = (y_df[\"split\"]==\"train\").values\n",
    "val_mask   = (y_df[\"split\"]==\"val\").values\n",
    "test_mask  = (y_df[\"split\"]==\"test\").values\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "print(\"Splits:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "cls_names = sorted(y_df.drop_duplicates(\"class_id\")[[\"class_id\",\"class_name\"]].values.tolist(), key=lambda x: x[0])\n",
    "id2name = {int(i): n for i,n in cls_names}\n",
    "name2id = {n:i for i,n in id2name.items()}\n",
    "id2name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1495bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build tf.data pipelines\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_ds(X, y, batch, training=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(10000, len(X)))\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(X_train, y_train, BATCH_SIZE, training=True)\n",
    "val_ds   = make_ds(X_val,   y_val,   BATCH_SIZE, training=False)\n",
    "test_ds  = make_ds(X_test,  y_test,  BATCH_SIZE, training=False)\n",
    "\n",
    "len_train = len(list(iter(train_ds)))\n",
    "print(\"Batches per epoch (train):\", len_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model: EfficientNetB0 for speed (can bump to B3 if you have GPU)\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "base = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), weights=None)\n",
    "# Note: weights=None because this is a tiny synthetic dataset. You can try ImageNet weights for real photos.\n",
    "base.trainable = True\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base(inputs, training=True)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60155fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train\n",
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ed8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(\"Test acc:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model and class index mapping\n",
    "model.save(MODEL_OUT)\n",
    "with open(CLASS_INDEX_JSON, \"w\") as f:\n",
    "    json.dump(id2name, f, indent=2)\n",
    "print(\"Saved:\", MODEL_OUT, CLASS_INDEX_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c902f",
   "metadata": {},
   "source": [
    "\n",
    "### Quick inference utility\n",
    "Upload or pick an image from the synthetic arrays and run a prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acee699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_one(img):\n",
    "    # img should be float32 [0,1], shape (H,W,3)\n",
    "    import numpy as np\n",
    "    arr = np.expand_dims(img, 0)\n",
    "    probs = model.predict(arr, verbose=0)[0]\n",
    "    top = int(np.argmax(probs))\n",
    "    return top, float(probs[top]), probs\n",
    "\n",
    "# Try a few from test split\n",
    "import matplotlib.pyplot as plt\n",
    "idxs = np.where(test_mask)[0][:8]\n",
    "plt.figure(figsize=(12,6))\n",
    "for i,k in enumerate(idxs[:8]):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    pred, p, probs = predict_one(X[k])\n",
    "    plt.imshow(X[k])\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"pred={id2name[pred]} ({p:.2f})\\ntrue={id2name[int(y[k])]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cdc50",
   "metadata": {},
   "source": [
    "\n",
    "### Grad-CAM (optional explainability)\n",
    "This visualizes *where* the model is focusing. (Crude but useful for demos.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lightweight Grad-CAM\n",
    "import numpy as np, tensorflow as tf, matplotlib.pyplot as plt\n",
    "\n",
    "# pick the last conv layer from EfficientNetB0\n",
    "last_conv = None\n",
    "for layer in model.layers[::-1]:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        last_conv = layer.name\n",
    "        break\n",
    "if last_conv is None:\n",
    "    # fallback: search inside the EfficientNet base\n",
    "    for layer in base.layers[::-1]:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv = layer.name\n",
    "            break\n",
    "print(\"Using last conv layer:\", last_conv)\n",
    "\n",
    "def grad_cam(img, class_index=None):\n",
    "    img_in = tf.expand_dims(img, 0)\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(img_in)\n",
    "        if class_index is None:\n",
    "            class_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, class_index]\n",
    "    grads = tape.gradient(class_channel, conv_out)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "    conv_out = conv_out[0]\n",
    "    heatmap = conv_out @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def overlay_heatmap(img, heatmap, alpha=0.4):\n",
    "    import cv2\n",
    "    hm = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    hm = np.uint8(255 * hm)\n",
    "    hm = cv2.applyColorMap(hm, cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_RGB2BGR), 1.0, hm, alpha, 0)\n",
    "    return cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Demo on one test image\n",
    "k = int(np.where(test_mask)[0][0])\n",
    "pred, p, _ = predict_one(X[k])\n",
    "hm = grad_cam(X[k], class_index=pred)\n",
    "ov = overlay_heatmap(X[k], hm, alpha=0.45)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.imshow(X[k]); plt.axis(\"off\"); plt.title(f\"Input\\ntrue={id2name[int(y[k])]}, pred={id2name[pred]}\")\n",
    "plt.subplot(1,2,2); plt.imshow(ov); plt.axis(\"off\"); plt.title(\"Grad-CAM overlay\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
